{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b33a4db-d3b5-4de7-a829-712799247371",
   "metadata": {},
   "source": [
    "# HW from CPC\n",
    "\n",
    "\n",
    "CPC Global Unified Temperature data products from PSL\n",
    "\n",
    "Citation Please note: If you acquire CPC Global Unified Temperature data products from PSL, we ask that you acknowledge us in your use \n",
    "of the data. This may be done by including text such as CPC Global Unified Temperature data provided by the NOAA PSL, Boulder, Colorado, USA,\n",
    "from their website at https://psl.noaa.gov in any documents or publications using these data. We would also appreciate receiving a copy of \n",
    "the relevant publications. This will help PSL to justify keeping the data freely available online in the future. Thank you!\n",
    "\n",
    "Opendap\n",
    "download: https://psl.noaa.gov/thredds/catalog/Datasets/cpc_global_temp/catalog.html?dataset=Datasets/cpc_global_temp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268adf25-1925-41e7-a08e-38198e7e5613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import netCDF4\n",
    "import time\n",
    "from netCDF4 import Dataset\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime\n",
    "from scipy import signal\n",
    "#from pylab import *\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import time\n",
    "\n",
    "\n",
    "from xarray.backends import NetCDF4DataStore\n",
    "import xarray as xr\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30541d65-52d9-4dfd-9d60-ccfffc3cf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_CPC_opendap(start,end):\n",
    "    \"\"\"downloading CPC from opendap\"\"\"\n",
    "    time_range = np.arange(start,end+1)\n",
    "    tmax = {}\n",
    "    if start <1979:\n",
    "        print('Start should be >=1979')\n",
    "    else:\n",
    "        for e,u in enumerate(time_range):\n",
    "            print(e,u)\n",
    "            url = 'http://psl.noaa.gov/thredds/dodsC/Datasets/cpc_global_temp/tmax.%s.nc'%u\n",
    "            nc = Dataset(url).variables\n",
    "            lon = nc['lon'][:]\n",
    "            lat = nc['lat'][:]\n",
    "            # BRAZIL section\n",
    "            lon_min= np.abs(lon[:] -(360-75)).argmin()\n",
    "            lon_max= np.abs(lon[:] -(360-34)).argmin()\n",
    "            \n",
    "            lat_min= np.abs(lat[:] -(6)).argmin()\n",
    "            lat_max= np.abs(lat[:] -(-35)).argmin()\n",
    "            tmax[e] = ma.masked_values(nc['tmax'][:,lat_min:lat_max,lon_min:lon_max],nc['tmax'].missing_value)\n",
    "            #print(tmax.shape)\n",
    "            #time, lats,lons = tmax.shape\n",
    "            #HW = {} #ma.masked_all((lats,lons))\n",
    "            \n",
    "            #for i in range (lats):\n",
    "            #    for j in range(lons):\n",
    "            #        HW = HEATWAVE_SUM_YEAR(tmax[:,i,j],tmaxclim[i,j])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return tmax\n",
    "CPC_tmax = download_CPC_opendap(2011,2023)\n",
    "CPC_clim = download_CPC_opendap(1981,2010)\n",
    "\n",
    "import pickle\n",
    "path = '/Users/calim/code/CEMADEN/data/'\n",
    "pickle.dump(CPC_clim, open( path+\"CPC_1981_2010.p\", \"wb\" ) )\n",
    "pickle.dump(CPC_tmax, open( path+\"CPC_tmax.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc348916-9e02-482b-9749-61cf310b1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "confind = 95 # 95% above 3 consecutives days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c28771-e498-49e3-9741-3c69959108f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i,j=0,0\n",
    "#time, lats,lons = tmax_2011.shape\n",
    "#heatwave={}\n",
    "#for i in range (lats):\n",
    "#    for j in range(lons):\n",
    "def HEATWAVE_SUM_YEAR(tmax,tmax_clim):\n",
    "    \"\"\"Heat wave \n",
    "       periods of consecutive days with Tmax values above a certain percentile of \n",
    "       Tmax for the particular calendar day (calculated on a 15 day window). \n",
    "       Different percentiles (80th, 90th, 95th) \n",
    "       return:\n",
    "       np.mean(HW) = mean temp of a HW\n",
    "       np.sum(htwv_amp) = total days under HW\n",
    "       len(htwv_amp) = frequency of HW\n",
    "       np.mean(htwv_amp) = duration of HW\n",
    "    \"\"\"\n",
    "    #heatwave[i,j] = np.where(tmax[:,i,j]>tmax_clim[i,j])[0]\n",
    "    heatwave = np.where(tmax>tmax_clim)[0]\n",
    "    #print(heatwave[i,j])\n",
    "    prev=np.zeros(len(heatwave)+1)\n",
    "    low=np.zeros(len(heatwave))\n",
    "    count=0 \n",
    "    for a in range (1,len(heatwave)):\n",
    "        if heatwave[a] == heatwave[a-1]+1:  #loop each index above confind%\n",
    "            count+=1                              #if days consecutive add 1\n",
    "            prev[a]=count \n",
    "        else:\n",
    "            count =0                              #if day is not consecutive =0\n",
    "    np.where(prev==0)[0]\n",
    "    low = []\n",
    "    low = np.where(prev==0)[0] #SEARCH FOR EMPTY SPACES\n",
    "    htwv_amp,HW=[],[]\n",
    "    days_hw =[]\n",
    "    for b in range (1,len(low)):\n",
    "        above90 = heatwave[low[b-1]:low[b]] \n",
    "        if b == len(low):\n",
    "            above90 =(heatwave[low[b-1]:len(low)])\n",
    "        if (len(above90)>=3):\n",
    "            htwv_amp.append(len(above90)) # HW amplitude\n",
    "            days_hw.append(above90[0])\n",
    "\n",
    "    return np.sum(htwv_amp),len(htwv_amp),(ma.mean(htwv_amp))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fca248-8c55-47bb-8124-b77d173571bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = '/user/data/'\n",
    "#CPC_clim = pickle.load(open(path+\"CPC_1981_2010.p\", 'rb'))\n",
    "CPC_tmax = pickle.load(open(path+\"CPC_tmax.p\", 'rb'))\n",
    "#CPC_clim_y = pickle.load(open(path+\"CPC_clim_y\", 'rb'))\n",
    "CPC_clim_y_90 = pickle.load(open(path+\"CPC_clim_y_90.p\", 'rb'))\n",
    "\n",
    "time, lats,lons = CPC_tmax[0].shape\n",
    "HW, freqHW,durHW = ma.masked_all((len(CPC_tmax),lats,lons)),ma.masked_all((len(CPC_tmax),lats,lons)),ma.masked_all((len(CPC_tmax),lats,lons))\n",
    "for e in range (len(CPC_tmax)):\n",
    "\n",
    "    for i in range (lats):\n",
    "        for j in range(lons):\n",
    "            HW[e,i,j],freqHW[e,i,j],durHW[e,i,j] = HEATWAVE_SUM_YEAR(CPC_tmax[e][:,i,j],tmax_clim_annual[i,j])\n",
    "\n",
    "import pickle\n",
    "path = '/user/data/'\n",
    "pickle.dump(HW, open( path+\"HW.p\", \"wb\" ) )\n",
    "pickle.dump(freqHW, open( path+\"freqHW.p\", \"wb\" ) )\n",
    "pickle.dump(durHW, open( path+\"durHW.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
