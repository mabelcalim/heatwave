{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4461ae4-fccf-4b29-ab43-91526fd975b6",
   "metadata": {},
   "source": [
    "# ERA5 Heatwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6caaae-e8cd-4e60-a92b-193fd6e887a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%pylab inline\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime\n",
    "from scipy import signal\n",
    "#from pylab import *\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff3e7c-c4c3-4f61-90e6-0022d8317ff0",
   "metadata": {},
   "source": [
    "# 1.  Download data from ERA5 \n",
    "\n",
    "Use ERA5_month_download.py to download monthly separated data. \n",
    "Set area, path for download and time inside the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f852f55-4e03-4d63-a111-6fcc16819036",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ERA5_month_download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa68fc2-07f9-423e-9ec3-f204a7bdab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confind = 95 # 95% above 3 consecutives days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275bfc2-a7b2-4eb0-93fa-74fe4eb0c37d",
   "metadata": {},
   "source": [
    "# 2. ERA5 combine expver1 +expver5¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18915a5e-c598-4263-bf8f-a16729afb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5 = xr.open_mfdataset(path+'ERA5_monthly_12_8123.nc',combine='by_coords')\n",
    "ERA5_combine =ERA5.sel(expver=1).combine_first(ERA5.sel(expver=5))\n",
    "ERA5_combine.load()\n",
    "ERA5_combine.to_netcdf(path+\"ERA5_monthly_12_8123_expver_combine.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaea878-8e11-48c9-af72-de95f306913b",
   "metadata": {},
   "source": [
    "# 3. Find Heatwave inside months blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6f8eba-32f4-4ae7-9920-fce85db4d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_block(path,var,month):\n",
    "    \"\"\"ERA5 hourly data to months blocks\n",
    "    \"\"\"\n",
    "    f = Dataset(path)\n",
    "    nc = f.variables\n",
    "    if month == '31':  \n",
    "        bsize = 31*24   #(31 days = 744 hours) \n",
    "        t,la,lo=nc[var].shape\n",
    "        print(nc[var].shape)\n",
    "        lmonth= int(t/bsize)\n",
    "    elif month == '30':\n",
    "        bsize = 30*24   #(30 days = 720 hours) \n",
    "        t,la,lo=nc[var].shape\n",
    "        print(nc[var].shape)\n",
    "        lmonth= int(t/bsize) \n",
    "    elif month == '28':\n",
    "        bsize = 28*24   #(30 days = 720 hours) \n",
    "        t,la,lo=nc[var].shape\n",
    "        print(nc[var].shape)\n",
    "        lmonth= int(t/bsize)\n",
    "    elif month == '29':\n",
    "        bsize = 30*24   #(30 days = 720 hours) \n",
    "        t,la,lo=nc[var].shape\n",
    "        print(nc[var].shape)\n",
    "        lmonth= int(t/bsize)\n",
    "    x, u,v={},{},{}\n",
    "    x_mean = ma.masked_all((lmonth,la,lo))\n",
    "    for i in range (lmonth):\n",
    "        if var == 't2m':\n",
    "            x[i] = nc[var][i*bsize:(i+1)*bsize]- 273.15 # from K to C\n",
    "            x_mean[i] = x[i].mean(axis=0)     \n",
    "        elif var == 'tp':\n",
    "            x[i] = nc[var][i*bsize:(i+1)*bsize]*1000*24 # from m to mm\n",
    "            x_mean[i] = x[i].mean(axis=0) \n",
    "        elif var == 'd2m':\n",
    "            x[i] = nc[var][i*bsize:(i+1)*bsize]- 273.15 # from K to C\n",
    "            x_mean[i] = x[i].mean(axis=0) \n",
    "        elif var == 'u10':\n",
    "            u[i] = nc['u10'][i*bsize:(i+1)*bsize]*3.6  #m/s to km/h\n",
    "            v[i] = nc['v10'][i*bsize:(i+1)*bsize]*3.6  #m/s to km/h\n",
    "            x[i] = np.sqrt((u[i]**2) + (v[i]**2))\n",
    "            x_mean[i] = x[i].mean(axis=0) \n",
    "            \n",
    "\n",
    "    return x,x_mean\n",
    "\n",
    "def month_block_feb(path,var):\n",
    "    \"\"\"ERA5 hourly data to months blocks\n",
    "    \"\"\"\n",
    "    f = Dataset(path)\n",
    "    nc = f.variables\n",
    "    t,la,lo=nc[var].shape\n",
    "    biss = [28,28,28,29]*10\n",
    "    biss = biss+[28] #add 2021\n",
    "    x ={}\n",
    "    \n",
    "    for i in biss:\n",
    "        \n",
    "        bsize = i *24\n",
    "        lmonth= int(t/bsize)\n",
    "        x_mean = ma.masked_all((lmonth,la,lo))\n",
    "        for i in range(lmonth):\n",
    "             if var == 't2m':\n",
    "                x[i] = nc[var][i*bsize:(i+1)*bsize]- 273.15 # from K to C\n",
    "                x_mean[i] = x[i].mean(axis=0) \n",
    "    return x,x_mean\n",
    "\n",
    "def daily_block (var,stats):\n",
    "    \"\"\"Daily block average\n",
    "    Input\n",
    "    ------\n",
    "    var : array\n",
    "        hourly data\n",
    "    stats : string\n",
    "        choose between mean and max\n",
    "    \"\"\"\n",
    "    #print(stats)\n",
    "    t,la,lo=var.shape\n",
    "    bsize = 24      # 24 hours = 1 day\n",
    "    lmonth= int(t/24)\n",
    "    x = ma.masked_all((lmonth,la,lo))\n",
    "    \n",
    "    for i in range (lmonth):\n",
    "        if stats == 'max':\n",
    "            x[i]  = var[i*bsize:(i+1)*bsize].max(axis=0) #1day window find max temp\n",
    "            #x[i].mean(axis=1).mean(axis=1)  \n",
    "        elif stats == 'mean':\n",
    "            x[i] = var[i*bsize:(i+1)*bsize].mean(axis=0)\n",
    "        elif stats =='min':\n",
    "            x[i]  = var[i*bsize:(i+1)*bsize].min(axis=0)            \n",
    "            \n",
    "        #from sklearn.linear_model import LinearRegression\n",
    "        #model = LinearRegression()\n",
    "        #model.fit(time,set20)\n",
    "        #trend=model.predict(set20)\n",
    "        else:\n",
    "            print(\"Choose between 'mean', 'max' and 'sum'\")\n",
    "                                                     \n",
    "    return x #signal.detrend(x)\n",
    "\n",
    "def climatology(temp):\n",
    "    days,lat,lon = temp[0].shape\n",
    "    years = len(temp.keys())\n",
    "    #years =41 #30 1981-2010\n",
    "    ts=ma.masked_all((years,days))\n",
    "    sp = ma.masked_all((years,lat,lon))\n",
    "    clim = np.zeros(days)\n",
    "    for i in range(years):\n",
    "        ts[i] = temp[i].mean(axis=1).mean(axis=1)\n",
    "    # range clim for each day\n",
    "    for i in range(years):\n",
    "        for j in range(days):\n",
    "            clim[j] = clim[j]+ts[i][j]\n",
    "            #print (i,j,ts[i][j], clim[j])\n",
    "\n",
    "    return clim/years\n",
    "\n",
    "\n",
    "def HeatWave_ts (ts,clim95):\n",
    "    \"\"\"Heat wave \n",
    "       periods of consecutive days with Tmax values above a certain percentile of \n",
    "       Tmax for the particular calendar day (calculated on a 15 day window). \n",
    "       Different percentiles (80th, 90th, 95th) and durations (3–4 days, 5–7 days, >7 days) \n",
    "       return:\n",
    "       np.mean(HW) = mean temp of a HW\n",
    "       np.sum(htwv_amp) = total days under HW\n",
    "       len(htwv_amp) = frequency of HW\n",
    "       np.mean(htwv_amp) = duration of HW\n",
    "    \"\"\"\n",
    "    # found all heat waves above 95 percentil\n",
    "    hw_where = np.where(ts>clim95)\n",
    "    heat_wave =np.zeros(len(ts))\n",
    "    for i in range (len(ts)):\n",
    "        if ts[i]>clim95[i]:\n",
    "            heat_wave[i]= ts[i]\n",
    "    #search for consecutives days\n",
    "    prev=np.zeros(len(hw_where[0])+1)             # plus 1 to add last group of heatwave\n",
    "    count=0 \n",
    "    low=np.zeros(len(hw_where[0]))\n",
    "    for i in range (1,len(hw_where[0])):\n",
    "        if hw_where[0][i] == hw_where[0][i-1]+1:  #loop each index above confind\n",
    "            count+=1                              #if days consecutive add 1\n",
    "            prev[i]=count \n",
    "        else:\n",
    "            count =0                              #if day is not consecutive =0\n",
    "    #search for zeros to found the separate classes of heatwaves\n",
    "    low = []\n",
    "    low = np.where(prev==0)[0] #SEARCH FOR EMPTY SPACES\n",
    "    htwv_amp,HW=[],[]\n",
    "\n",
    "    for i in range (1,len(low)):\n",
    "        above95 = hw_where[0][low[i-1]:low[i]] \n",
    "        if i == len(low):\n",
    "            above95 =(hw_where[0][low[i-1]:len(low)])\n",
    "        if (len(above95)>=3):\n",
    "            htwv_amp.append(len(above95)) # HW amplitude\n",
    "            HW.append(np.max(heat_wave[above95]))\n",
    "            \n",
    "        else:   \n",
    "            htwv_amp.append(0)\n",
    "            HW.append(0)\n",
    "            #htwv_count=len(htwv_amp)\n",
    "        #elif (len(above95)<=7)&(len(above95)>=5): #can separate in categories 5-7 days\n",
    "        #    htwv2.append(above95)\n",
    "        #elif (len(above95)>=7): # category >7 days\n",
    "        #    htwv3.append(above95)  \n",
    "    return np.mean(HW),np.sum(htwv_amp), len(htwv_amp), np.mean(htwv_amp) \n",
    "\n",
    "def HW_dict(index):\n",
    "    path= '/Users/calim/code/CEMADEN/'\n",
    "    f = Dataset(path+'ERA5_Sept_2020.nc') #JUST TO PICK LAT AND LON\n",
    "    nc = f.variables\n",
    "    time,lat,lon = nc['t2m'].shape \n",
    "    HWjan,HWfeb,HWmar,HWapr =ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    HWmay,HWjun,HWjul,HWaug = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    HWsep,HWoct,HWnov,HWdec = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    " \n",
    "    \n",
    "    hwjan,hwfeb,hwmar,hwapr =ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    hwmay,hwjun,hwjul,hwaug = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    hwsep,hwoct,hwnov,hwdec = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    " \n",
    "    ahwjan,ahwfeb,ahwmar,ahwapr =ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    ahwmay,ahwjun,ahwjul,ahwaug = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    ahwsep,ahwoct,ahwnov,ahwdec = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    " \n",
    "    shwjan,shwfeb,shwmar,shwapr =ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    shwmay,shwjun,shwjul,shwaug = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    "    shwsep,shwoct,shwnov,shwdec = ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon)),ma.masked_all((lat,lon))\n",
    " \n",
    "\n",
    "\n",
    "    #index=38\n",
    "\n",
    "    for i in range(lat):\n",
    "        for j in range (lon):\n",
    "                HWjan[i,j],shwjan[i,j],hwjan[i,j],ahwjan[i,j] = HeatWave_ts(tmax1[index][:,i,j],clim_95_1)\n",
    "                HWfeb[i,j],shwfeb[i,j],hwfeb[i,j],ahwfeb[i,j] = HeatWave_ts(tmax2[index][:,i,j],clim_95_2)\n",
    "                HWmar[i,j],shwmar[i,j],hwmar[i,j],ahwmar[i,j] = HeatWave_ts(tmax3[index][:,i,j],clim_95_3)\n",
    "                HWapr[i,j],shwapr[i,j],hwapr[i,j],ahwapr[i,j] = HeatWave_ts(tmax4[index][:,i,j],clim_95_4)\n",
    "                HWmay[i,j],shwmay[i,j],hwmay[i,j],ahwmay[i,j] = HeatWave_ts(tmax5[index][:,i,j],clim_95_5)\n",
    "                HWjun[i,j],shwjun[i,j],hwjun[i,j],ahwjun[i,j] = HeatWave_ts(tmax6[index][:,i,j],clim_95_6)\n",
    "                HWjul[i,j],shwjul[i,j],hwjul[i,j],ahwjul[i,j] = HeatWave_ts(tmax7[index][:,i,j],clim_95_7)\n",
    "                HWaug[i,j],shwaug[i,j],hwaug[i,j],ahwaug[i,j] = HeatWave_ts(tmax8[index][:,i,j],clim_95_8)            \n",
    "                HWsep[i,j],shwsep[i,j],hwsep[i,j],ahwsep[i,j] = HeatWave_ts(tmax9[index][:,i,j],clim_95_9)\n",
    "                HWoct[i,j],shwoct[i,j],hwoct[i,j],ahwoct[i,j] = HeatWave_ts(tmax10[index][:,i,j],clim_95_10)\n",
    "                HWnov[i,j],shwnov[i,j],hwnov[i,j],ahwnov[i,j] = HeatWave_ts(tmax11[index][:,i,j],clim_95_11)\n",
    "                HWdec[i,j],shwdec[i,j],hwdec[i,j],ahwdec[i,j] = HeatWave_ts(tmax12[index][:,i,j],clim_95_12)              \n",
    "\n",
    "                #sum_hw19[i,j] = HeatWave_ts(tmax10[38][:,i,j],clim_95_10)\n",
    "                #sum_hw20[i,j] = HeatWave_ts(tmax10[39][:,i,j],clim_95_10)\n",
    "                #sum_hw21[i,j] = HeatWave_ts(tmax10[40][:,i,j],clim_95_10)\n",
    "    HW ={}\n",
    "    HW[0]= [] \n",
    "    HW[1] =HWjan\n",
    "    HW[2]= HWfeb\n",
    "    HW[3]= HWmar\n",
    "    HW[4]= HWapr\n",
    "    HW[5]= HWmay\n",
    "    HW[6]= HWjun\n",
    "    HW[7]= HWjul\n",
    "    HW[8]= HWaug\n",
    "    HW[9]= HWsep\n",
    "    HW[10]= HWoct\n",
    "    HW[11]= HWnov\n",
    "    HW[12]= HWdec\n",
    "                \n",
    "    hw ={}\n",
    "    hw[0]= [] \n",
    "    hw[1] =hwjan\n",
    "    hw[2]= hwfeb\n",
    "    hw[3]= hwmar\n",
    "    hw[4]= hwapr\n",
    "    hw[5]= hwmay\n",
    "    hw[6]= hwjun\n",
    "    hw[7]= hwjul\n",
    "    hw[8]= hwaug\n",
    "    hw[9]= hwsep\n",
    "    hw[10]= hwoct\n",
    "    hw[11]= hwnov\n",
    "    hw[12]= hwdec\n",
    "\n",
    "    ahw ={}\n",
    "    ahw[0]= [] \n",
    "    ahw[1] =ahwjan\n",
    "    ahw[2]= ahwfeb\n",
    "    ahw[3]= ahwmar\n",
    "    ahw[4]= ahwapr\n",
    "    ahw[5]= ahwmay\n",
    "    ahw[6]= ahwjun\n",
    "    ahw[7]= ahwjul\n",
    "    ahw[8]= ahwaug\n",
    "    ahw[9]= ahwsep\n",
    "    ahw[10]= ahwoct\n",
    "    ahw[11]= ahwnov\n",
    "    ahw[12]= ahwdec\n",
    "    \n",
    "    \n",
    "    shw ={}\n",
    "    shw[0]= [] \n",
    "    shw[1] =shwjan\n",
    "    shw[2]= shwfeb\n",
    "    shw[3]= shwmar\n",
    "    shw[4]= shwapr\n",
    "    shw[5]= shwmay\n",
    "    shw[6]= shwjun\n",
    "    shw[7]= shwjul\n",
    "    shw[8]= shwaug\n",
    "    shw[9]= shwsep\n",
    "    shw[10]= shwoct\n",
    "    shw[11]= shwnov\n",
    "    shw[12]= shwdec\n",
    "    return HW,hw,ahw,shw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246cd51-9381-43f4-a0dc-cc5042fdffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = Dataset(path+'ERA5_01_8123.nc') #JUST TO PICK LAT AND LON\n",
    "nc = f.variables\n",
    "time,lat,lon = nc['t2m'].shape \n",
    "\n",
    "sum_hw19 = ma.masked_all((lat,lon))\n",
    "sum_hw20 = ma.masked_all((lat,lon))\n",
    "sum_hw21 = ma.masked_all((lat,lon))\n",
    "\n",
    "HW2018,hw2018,ahw2018,shw2018 = HW_dict(37)\n",
    "HW2019,hw2019,ahw2019,shw2019 = HW_dict(38)\n",
    "HW2020,hw2020,ahw2020,shw2020 = HW_dict(39)\n",
    "HW2021,hw2021,ahw2021,shw2021 = HW_dict(40)\n",
    "HW2022,hw2022,ahw2022,shw2022 = HW_dict(41)\n",
    "#hw2022 = HW_dict(37)\n",
    "\n",
    "HW1921={}\n",
    "HW1921[0]=HW2018[12]\n",
    "HW1921[1] =HW2019[1]\n",
    "HW1921[2]= HW2019[2]\n",
    "HW1921[3]= HW2019[3]\n",
    "HW1921[4]= HW2019[4]\n",
    "HW1921[5]= HW2019[5]\n",
    "HW1921[6]= HW2019[6]\n",
    "HW1921[7]= HW2019[7]\n",
    "HW1921[8]= HW2019[8]\n",
    "HW1921[9]= HW2019[9]\n",
    "HW1921[10]= HW2019[10]\n",
    "HW1921[11]= HW2019[11]\n",
    "HW1921[12]= HW2019[12]\n",
    "\n",
    "HW1921[13]= HW2020[1]\n",
    "HW1921[14]= HW2020[2]\n",
    "HW1921[15]= HW2020[3]\n",
    "HW1921[16]= HW2020[4]\n",
    "HW1921[17]= HW2020[5]\n",
    "HW1921[18]= HW2020[6]\n",
    "HW1921[19]= HW2020[7]\n",
    "HW1921[20]= HW2020[8]\n",
    "HW1921[21]= HW2020[9]\n",
    "HW1921[22]= HW2020[10]\n",
    "HW1921[23]= HW2020[11]\n",
    "HW1921[24]= HW2020[12]\n",
    "\n",
    "HW1921[25]= HW2021[1]\n",
    "HW1921[26]= HW2021[2]\n",
    "HW1921[27]= HW2021[3]\n",
    "HW1921[28]= HW2021[4]\n",
    "HW1921[29]= HW2021[5]\n",
    "HW1921[30]= HW2021[6]\n",
    "HW1921[31]= HW2021[7]\n",
    "HW1921[32]= HW2021[8]\n",
    "HW1921[33]= HW2021[9]\n",
    "HW1921[34]= HW2021[10]\n",
    "HW1921[35]= HW2021[11]\n",
    "HW1921[36]= HW2021[12]\n",
    "HW1921[37]= HW2022[1]\n",
    "HW1921[38]= HW2022[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hw1921={}\n",
    "hw1921[0]=hw2018[12]\n",
    "hw1921[1] =hw2019[1]\n",
    "hw1921[2]= hw2019[2]\n",
    "hw1921[3]= hw2019[3]\n",
    "hw1921[4]= hw2019[4]\n",
    "hw1921[5]= hw2019[5]\n",
    "hw1921[6]= hw2019[6]\n",
    "hw1921[7]= hw2019[7]\n",
    "hw1921[8]= hw2019[8]\n",
    "hw1921[9]= hw2019[9]\n",
    "hw1921[10]= hw2019[10]\n",
    "hw1921[11]= hw2019[11]\n",
    "hw1921[12]= hw2019[12]\n",
    "\n",
    "hw1921[13]= hw2020[1]\n",
    "hw1921[14]= hw2020[2]\n",
    "hw1921[15]= hw2020[3]\n",
    "hw1921[16]= hw2020[4]\n",
    "hw1921[17]= hw2020[5]\n",
    "hw1921[18]= hw2020[6]\n",
    "hw1921[19]= hw2020[7]\n",
    "hw1921[20]= hw2020[8]\n",
    "hw1921[21]= hw2020[9]\n",
    "hw1921[22]= hw2020[10]\n",
    "hw1921[23]= hw2020[11]\n",
    "hw1921[24]= hw2020[12]\n",
    "\n",
    "hw1921[25]= hw2021[1]\n",
    "hw1921[26]= hw2021[2]\n",
    "hw1921[27]= hw2021[3]\n",
    "hw1921[28]= hw2021[4]\n",
    "hw1921[29]= hw2021[5]\n",
    "hw1921[30]= hw2021[6]\n",
    "hw1921[31]= hw2021[7]\n",
    "hw1921[32]= hw2021[8]\n",
    "hw1921[33]= hw2021[9]\n",
    "hw1921[34]= hw2021[10]\n",
    "hw1921[35]= hw2021[11]\n",
    "hw1921[36]= hw2021[12]\n",
    "hw1921[37]= hw2022[1]\n",
    "hw1921[38]= hw2022[2]\n",
    "\n",
    "\n",
    "\n",
    "ahw1921={}\n",
    "ahw1921[0]= ahw2018[12]\n",
    "ahw1921[1] = ahw2019[1]\n",
    "ahw1921[2]= ahw2019[2]\n",
    "ahw1921[3]= ahw2019[3]\n",
    "ahw1921[4]= ahw2019[4]\n",
    "ahw1921[5]= ahw2019[5]\n",
    "ahw1921[6]= ahw2019[6]\n",
    "ahw1921[7]= ahw2019[7]\n",
    "ahw1921[8]= ahw2019[8]\n",
    "ahw1921[9]= ahw2019[9]\n",
    "ahw1921[10]= ahw2019[10]\n",
    "ahw1921[11]= ahw2019[11]\n",
    "ahw1921[12]= ahw2019[12]\n",
    "\n",
    "ahw1921[13]= ahw2020[1]\n",
    "ahw1921[14]= ahw2020[2]\n",
    "ahw1921[15]= ahw2020[3]\n",
    "ahw1921[16]= ahw2020[4]\n",
    "ahw1921[17]= ahw2020[5]\n",
    "ahw1921[18]= ahw2020[6]\n",
    "ahw1921[19]= ahw2020[7]\n",
    "ahw1921[20]= ahw2020[8]\n",
    "ahw1921[21]= ahw2020[9]\n",
    "ahw1921[22]= ahw2020[10]\n",
    "ahw1921[23]= ahw2020[11]\n",
    "ahw1921[24]= ahw2020[12]\n",
    "\n",
    "ahw1921[25]= ahw2021[1]\n",
    "ahw1921[26]= ahw2021[2]\n",
    "ahw1921[27]= ahw2021[3]\n",
    "ahw1921[28]= ahw2021[4]\n",
    "ahw1921[29]= ahw2021[5]\n",
    "ahw1921[30]= ahw2021[6]\n",
    "ahw1921[31]= ahw2021[7]\n",
    "ahw1921[32]= ahw2021[8]\n",
    "ahw1921[33]= ahw2021[9]\n",
    "ahw1921[34]= ahw2021[10]\n",
    "ahw1921[35]= ahw2021[11]\n",
    "ahw1921[36]= ahw2021[12]\n",
    "ahw1921[37]= ahw2022[1]\n",
    "ahw1921[38]= ahw2022[2]\n",
    "\n",
    "\n",
    "\n",
    "shw1921={}\n",
    "shw1921[0]= shw2018[12]/31\n",
    "shw1921[1] = shw2019[1]/31\n",
    "shw1921[2]= shw2019[2]/28\n",
    "shw1921[3]= shw2019[3]/31\n",
    "shw1921[4]= shw2019[4]/30\n",
    "shw1921[5]= shw2019[5]/31\n",
    "shw1921[6]= shw2019[6]/30\n",
    "shw1921[7]= shw2019[7]/31\n",
    "shw1921[8]= shw2019[8]/31\n",
    "shw1921[9]= shw2019[9]/30\n",
    "shw1921[10]= shw2019[10]/31\n",
    "shw1921[11]= shw2019[11]/30\n",
    "shw1921[12]= shw2019[12]/31\n",
    "\n",
    "shw1921[13]= shw2020[1]/31\n",
    "shw1921[14]= shw2020[2]/29\n",
    "shw1921[15]= shw2020[3]/31\n",
    "shw1921[16]= shw2020[4]/30\n",
    "shw1921[17]= shw2020[5]/31\n",
    "shw1921[18]= shw2020[6]/30\n",
    "shw1921[19]= shw2020[7]/31\n",
    "shw1921[20]= shw2020[8]/31\n",
    "shw1921[21]= shw2020[9]/30\n",
    "shw1921[22]= shw2020[10]/31\n",
    "shw1921[23]= shw2020[11]/30\n",
    "shw1921[24]= shw2020[12]/31\n",
    "\n",
    "shw1921[25]= shw2021[1]/31\n",
    "shw1921[26]= shw2021[2]/28\n",
    "shw1921[27]= shw2021[3]/31\n",
    "shw1921[28]= shw2021[4]/30\n",
    "shw1921[29]= shw2021[5]/31\n",
    "shw1921[30]= shw2021[6]/30\n",
    "shw1921[31]= shw2021[7]/31\n",
    "shw1921[32]= shw2021[8]/31\n",
    "shw1921[33]= shw2021[9]/30\n",
    "shw1921[34]= shw2021[10]/31\n",
    "shw1921[35]= shw2021[11]/30\n",
    "shw1921[36]= shw2021[12]/31\n",
    "shw1921[37]= shw2022[1]/31\n",
    "shw1921[38]= shw2022[2]/28\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(hw1921, open( path+\"hw1921.p\", \"wb\" ) )\n",
    "pickle.dump(ahw1921, open( path+\"ahw1921.p\", \"wb\" ) )\n",
    "pickle.dump(shw1921, open( path+\"shw1921.p\", \"wb\" ) )\n",
    "pickle.dump(HW1921, open( path+\"HW1921.p\", \"wb\" ) )\n",
    "pickle.dump(clim95, open( path+\"clim95.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd4d2c-2140-405a-85ab-d27750d56bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
